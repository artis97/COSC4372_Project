{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b2bdb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data Loader\n",
    "#this will prepare training data for the model\n",
    "\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28ca2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import array_ops, math_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54d7622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self, image_dir, hr_image_size):\n",
    "        self.image_paths = [os.path.join(image_dir, x) for x in os.listdir(image_dir)]\n",
    "        self.image_size = hr_image_size\n",
    "    def _parse_image(self, image_path):\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        \n",
    "        if tf.keras.backend.image_data_format() == 'channels_last':\n",
    "            shape = array_ops.shape(image)[:2]\n",
    "        else:\n",
    "            shape = array_ops_shape(image)[1:]\n",
    "        cond = math_ops.reduce_all(shape >= tf.constant(self, image_size))\n",
    "        image = tf.cond(cond, lambda: tf.identity(image)), lambda: tf.image.resize(image, [self.image_size, self.image_size])\n",
    "        return image\n",
    "    def _random_crop(self, image):\n",
    "        image = tf.image.random_crop(image, [self.image_size, self.image_size, 3])\n",
    "        return image\n",
    "    def _high_low_res_pairs(self, high_res):\n",
    "        low_res = tf.image.resize(high_res, [self.image_size // 4 , self.image_size//4], method = 'bicubic')\n",
    "        return low_res, high_res\n",
    "    def _rescale(self, low_res, high_res):\n",
    "        high_res = high_res * 2.0 - 1.0\n",
    "        return low_res, high_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47248b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(self, batch_size, threads=4):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(self.image_paths)\n",
    "    dataset = dataset.map(self._parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(self._random_crop, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(self._high_low_res_pairs, num_parallel_calls=tf.data.experimental.AUTOTUNE) \n",
    "    dataset = dataset.map(self._rescale, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(30).batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6ed82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now We are creating the model architecture or brain of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df226c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05ccbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastSRGAN(object):\n",
    "    def __init__(self, args):\n",
    "        self.hr_height = args.hr.size\n",
    "        self.hr_width = args.hr.size\n",
    "        self.lr_height = self.hr_height // 4\n",
    "        self.lr_width = self.hr_width // 4\n",
    "        self.lr_shape = (self.lr_height, self.lr_width, 3)\n",
    "        self.hr_shape = (self.hr_height, self.hr_width, 3)\n",
    "        self.iteractions = 0\n",
    "        \n",
    "        self.n_residual_blocks = 6\n",
    "        self.gen_schedule = keras.optimizers.schedules.ExponentialDecay(args.lr, decay_steps=100000, decay_rate=0.1, staircase=True)\n",
    "        self.disc_schedule = keras.optimizers.schedules.ExponentialDecay(args.lr*5, decay_steps=100000, decay_rate=0.1, staircase=True)\n",
    "        \n",
    "        self.gen_optimizer = keras.optimizers.Adam(learning_rate=self.gen_schedule)\n",
    "        self.disc_optimizer = keras.optimizers.Adam(learning_rate=self.disc_schedule)\n",
    "        \n",
    "        self.vgg = self.build_vgg()\n",
    "        self.vgg.trainable = False\n",
    "        \n",
    "        patch = int(self.hr_height/2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "        \n",
    "        self.gf = 32\n",
    "        self.df = 32\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.generator = self.build_generator()\n",
    "    \n",
    "    @tf.function\n",
    "    def content_loss(self, hr, sr):\n",
    "        \n",
    "        sr = keras.applications.vgg19.preprocess_input(((sr+1.0)*255)/2.0)\n",
    "        hr = keras.applications.vgg19.preprocess_input(((sr+1.0)*255)/2.0)\n",
    "        sr_features = self.vgg(sr) / 12.75\n",
    "        hr_features = self.vgg(sr) / 12.75\n",
    "        return tf.keras.losses.MeanSquaredError()(hr_features, sr_features)\n",
    "    \n",
    "    def build_vgg(self):\n",
    "        vgg = keras.applications.VGG19(weights='imagenet', input_shape=self.hr_shape, include_top=False)\n",
    "        vgg.trainable = False\n",
    "        \n",
    "        for layer in vgg.layers:\n",
    "            layer.trainable = False\n",
    "            \n",
    "        model = keras.models.Model(inputs=vgg.input, outputs=vgg.get_layer(\"block5_conv4\").output)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def build_generator(self):\n",
    "        \n",
    "        def _make_divisible(v, divisor, min_value=None):\n",
    "            if min_value is None:\n",
    "                min_value = divisor\n",
    "            new_v = max(min_value, int(v+divisor/2) // divisor * divisor)\n",
    "            \n",
    "            if new_v < 0.9*v:\n",
    "                new_v += divisor\n",
    "            return new_v\n",
    "        def residual_block(inputs, filters, block_id, expansion=6, stride=1, alpha=1.0):\n",
    "            channel_axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
    "            \n",
    "            in_channels = keras.backend.int_shape(inputs)[channel_axis]\n",
    "            \n",
    "            pointwise_conv_filters = int(filters * alpha)\n",
    "            pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n",
    "            x = inputs\n",
    "            prefix = 'block_{}_'.format(block_id)\n",
    "            \n",
    "            if block_id:\n",
    "                \n",
    "                x = keras.layers.Conv2D(expansion * in_channels, kernel_size = 1, padding = 'same', use_bias=True, activation=None, name=prefix + 'expand')(x)\n",
    "                x = keras.layers.BatchNormalization(axis=channel_axis, epsilon=1e-3, padding = 'same', use_bias=True, activation=None, name=prefix + 'expand')(x)\n",
    "                x = keras.layers.Activation('relu', name=prefix + 'expand_relu')(x)\n",
    "            else:\n",
    "                prefix =  'expanded_conv_'\n",
    "                \n",
    "            x = keras.layers.DepthwiseConv2D(kernel_size=3,\n",
    "                                            strides=stride,\n",
    "                                            activation=None,\n",
    "                                            use_bias=True,\n",
    "                                            padding='same' if stride == 1 else 'valid',\n",
    "                                            name= prefix+'depthwise')(x)\n",
    "            x = keras.layers.BatchNormalization(axis=channel_axis,\n",
    "                                               epsilon=1e-3,\n",
    "                                               momentum=0.999,\n",
    "                                               name=prefix+'depthwise_BN')(x)\n",
    "            x = keras.layers.Activation('relu', name=prefix+'depthwise_relu')(x)\n",
    "            \n",
    "            x = keras.layers.Conv2D(pointwise_filters,\n",
    "                                   kernel_size = 1,\n",
    "                                   padding='same',\n",
    "                                   use_bias=True,\n",
    "                                   activation=None,\n",
    "                                   name=prefix+'project')(x)\n",
    "            \n",
    "            x = keras.layers.BatchNormalization(axis=channel_axis,\n",
    "                                               epsilon=1e-3,\n",
    "                                               momentum=0.999,\n",
    "                                               name=prefix+'project_BN')(x)\n",
    "            \n",
    "            if in_channels == pointwise_filters and stride == 1: \n",
    "                return keras.layers.Add(name=prefix+'add')([inputs, x]) \n",
    "            return x \n",
    "        \n",
    "        def deconv2D(layer_input, filters): \n",
    "            \n",
    "            u = keras.layers.Conv2D(filters, kernel_size=3, strides=1, padding='same')(layer_input) \n",
    "            u = tf.nn.depth_to_space(u,2) \n",
    "            u = keras.layers.PReLU(shared_axes=[1, 2])(u) \n",
    "            return u \n",
    "        \n",
    "        img_lr = keras.Input(shape=self.lr_shape) \n",
    "        \n",
    "        c1 = keras.layers.Conv2D(self.gf, kernel_size=3, strides=1, padding='same')(img_lr) \n",
    "        c1 = keras.layers.BatchNormalization()(c1)\n",
    "        c1 = keras.layers.PReLU(shared_axes=[1, 2])(c1) \n",
    "        r = residual_block(cl, self.gf, 0) \n",
    "        \n",
    "        for idx in range(1, self.n_residual_blocks):\n",
    "            r = residual_block(r, self.gf, idx) \n",
    "            \n",
    "        c2 = keras.layers.Conv2D(self.gf, kernel_size=3, strides=1, padding='same')(r)\n",
    "        c2 = keras.layers.BatchNormalization()(c2) \n",
    "        c2 = keras.layers.Add([c2, c1]) \n",
    "        \n",
    "        u1 = deconv2d(c2, self.gf*4) \n",
    "        u2 = deconv2d(u1, self.gf*4) \n",
    "        \n",
    "        gen_hr = keras.layers.Conv2D(3, kernel_size=3, strides=1, padding='same', activation='tanh')(u2) \n",
    "        return keras.models.Model(img_lr, gen_hr) \n",
    "    \n",
    "    \n",
    "    def build_discriminator(self): \n",
    "        \n",
    "        def d_block(layer_input, filters, strides=1, bn=True): \n",
    "            d = keras.layers.Conv2D(filters, kernel_size=3, strides = strides, padding='same')(layer_input) \n",
    "            if bn:\n",
    "                d = keras.layers.BatchNormalization(momentum=0.8)(d)\n",
    "            d = keras.layers.LeakyReLU(alpha=0.2)(d) \n",
    "            return d \n",
    "\n",
    "        d0 = keras.layers.input(shape=self.hr_shape)\n",
    "\n",
    "        d1 = d_block(d0, self.df, bn=False)\n",
    "        d2 = d_block(d1, self.df, strides=2) \n",
    "        d3 = d_block(d2, self.df) \n",
    "        d4 = d_block(d3, self.df, strides=2) \n",
    "        d5 = d_block(d4, self.df*2) \n",
    "        d6 = d_block(d5, self.df*2, strides=2) \n",
    "        d7 = d_block(d6, self.df*2) \n",
    "        d8 = d_block(d7, self.df*2, strides=2) \n",
    "\n",
    "        validity = keras.layers.Conv2D(1, kernel_size=1, strides=1, activation='sigmoid', padding='same')(d8) \n",
    "        return keras.models.Model(d0, validity) \n",
    "        \n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2baa4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d92d58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser() \n",
    "parser.add_argument('--image_dir', type=str, help='Path to high resolution image directory.') \n",
    "parser.add_argument('--batch_size', default=8, type=int, help='Batch size for training.') \n",
    "parser.add_argument('--epochs', default=1, type=int, help='Number of epochs for training') \n",
    "parser.add_argument('--hr_size', default=384, type=int, help='Low resolution input size.') \n",
    "parser.add_argument('--lr', default=1e-4, type=float, help='Learning rate for optimizers.') \n",
    "parser.add_argument('--save_iter', default=200, type=int, \n",
    "                    help='The number of iterations to save the tensorboard summaries and models.') \n",
    "@tf.function \n",
    "def pretrain_step(model, x, y): \n",
    "    \"\"\"\n",
    "    Single step of generator pre-training.\n",
    "    Args: \n",
    "        model: A model object with a tf keras compiled generator. \n",
    "        x: The low resolution image tensor. \n",
    "        y: The high resolution image tensor. \n",
    "    \"\"\"    \n",
    "        \n",
    "    with tf.GradientTape() as tape: \n",
    "        fake_hr = model.generator(x) \n",
    "        loss_mse = tf.keras.losses.MeanSquaredError()(y, fake_hr) \n",
    "    grads = tape.gradient(loss_mse, model.generator.trainable_variables)\n",
    "    model.gen_optimizer.apply_gradients(zip(grads, model.generator.trainable_variables)) \n",
    "    return loss_mse \n",
    "\n",
    "\n",
    "\n",
    "def pretrain_generator(model, dataset, writer):\n",
    "    \"\"\"Function that pretrains the generator slightly, to avoid local minima. \n",
    "    Args: \n",
    "        model: The keras model to train. \n",
    "        dataset: A tf dataset object of low and high res images to pretrain over. \n",
    "        writer: A summary writer object. \n",
    "    Returns: \n",
    "        None\n",
    "    \"\"\"\n",
    "    with writer.as_default(): \n",
    "        iteration = 0 \n",
    "        for _ in range(1): \n",
    "            for x, y in dataset: \n",
    "                loss = pretrain_step(model, x, y) \n",
    "                if iteration % 20 == 0: \n",
    "                    tf.summary.scalar('MSE Loss', loss, step=tf.cast(iteration, tf.int64)) \n",
    "                    writer.flush() \n",
    "                iteration += 1 \n",
    "@tf.function \n",
    "def train_step(model, x, y): \n",
    "    \"\"\"\n",
    "    Single train step function for the SRGAN. \n",
    "    Args: \n",
    "        model: An object that contains a tf keras compiled discriminator model. \n",
    "        x: The low resolution input image. \n",
    "        y: The desired high resolution output image. \n",
    "        Returns: \n",
    "        d_loss: The mean loss of the discriminator. \"\"\" \n",
    "    \n",
    "    # label smoothing for better gradient flow \n",
    "    valid = tf.ones((x.shape[0],) + model.disc_patch) \n",
    "    fake = tf.zeros((x.shape[0],) + model.disc_patch)\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: \n",
    "        # From Low res. image generate high res. version \n",
    "        fake_hr = model.generator(x) \n",
    "        # Train the discriminators (original images = real / generated = Fake) \n",
    "        valid_prediction = model.discriminator(y) \n",
    "        fake_prediction = model.discriminator(fake_hr) \n",
    "        # Generator Loss \n",
    "        content_loss = model.content_loss(y, fake_hr) \n",
    "        adv_loss = 1e-3 * tf.keras.losses.BinaryCrossentropy()(valid, fake_prediction)\n",
    "        mse_loss = tf.keras.losses.MeanSquaredError()(y, fake_hr) \n",
    "        perceptual_loss = content_loss + adv_loss + mse_loss \n",
    "        # Discriminator Loss \n",
    "        valid_loss = tf.keras.losses.BinaryCrossentropy()(valid, valid_prediction) \n",
    "        fake_loss = tf.keras.losses.BinaryCrossentropy()(fake, fake_prediction) \n",
    "        d_loss = tf.add(valid_loss, fake_loss) \n",
    "    # Backprop on Generator \n",
    "    gen_grads = gen_tape.gradient(perceptual_loss, model.generator.trainable_variables) \n",
    "    model.gen_optimizer.apply_gradients(zip(gen_grads, model.generator.trainable_variables)) \n",
    "    # Backprop on Discriminator \n",
    "    disc_grads = disc_tape.gradient(d_loss, model.discriminator.trainable_variables) \n",
    "    model.disc_optimizer.apply_gradients(zip(disc_grads, model.discriminator.trainable_variables)) \n",
    "    return d_loss, adv_loss, content_loss, mse_loss\n",
    "\n",
    "def train(model, dataset, log_iter, writer):\n",
    "    \"\"\"\"\n",
    "    Function that defines a single training step for the SR-GAN. \n",
    "    Args: \n",
    "        model: An object that contains tf keras compiled generator and \n",
    "                discriminator models. \n",
    "        dataset: A tf data object that contains low and high res images. \n",
    "        log_iter: Number of iterations after which to add logs in \n",
    "                  tensorboard. \n",
    "        writer: Summary writer \n",
    "    \"\"\"\n",
    "    with writer.as_default(): \n",
    "        # Iterate over dataset \n",
    "        for x, y in dataset: \n",
    "            disc_loss, adv_loss, content_loss, mse_loss = train_step(model, x, y)\n",
    "            # Log tensorboard summaries if Log iteration is reached. \n",
    "            if model.iterations % log_iter == 0: \n",
    "                tf.summary.scalar('Adversarial Loss', adv_loss, step=model.iterations) \n",
    "                tf.summary.scalar('Content Loss', content_loss, step=model.iterations) \n",
    "                tf.summary.scalar('MSE Loss', mse_loss, step=model.iterations) \n",
    "                tf.summary.scalar('Discriminator Loss', disc_loss, step=model.iterations) \n",
    "                tf.summary.image('Low Res', tf.cast(255 * x, tf.uint8), step=model.iterations) \n",
    "                tf.summary.image('High Res', tf.cast(255 * (y + 1.0) / 2.0, tf.uint8), step=model.iterations) \n",
    "                tf.summary.image('Generated', tf.cast(255 * (model.generator.predict(x) + 1.0) / 2.0, tf.uint8), \n",
    "                                 step=model.iterations) \n",
    "                model.generator.save('models/generator.h5') \n",
    "                model.discriminator.save('models/discriminator.h5')\n",
    "                writer.flush()     \n",
    "            model.iterations += 1\n",
    "            \n",
    "def main(): \n",
    "    # Parse the CLI arguments. \n",
    "    args = parser.parse_args() \n",
    "    \n",
    "    # create directory for saving troined models. \n",
    "    if not os.path.exists('models'): \n",
    "        os.makedirs('models') \n",
    "    # Create the tensorftow dataset. \n",
    "    ds = Dataloader(args.image_dir, args.hr_size).dataset(args.batch_size) \n",
    "    \n",
    "    # Initialize the GAN object. \n",
    "    gan = FastSRGAN(args) \n",
    "    \n",
    "    # Define the directory for saving pretrainig Loss tensorboard summary.\n",
    "    pretrain_summary_writer = tf.summary.create_file_writer('logs/pretrain') \n",
    "    # Run pre-training. \n",
    "    pretrain_generator(gan, ds, pretrain_summary_writer) \n",
    "    # Define the directory for saving the SRGAN training tensorboord summary. \n",
    "    train_summary_writer = tf.summary.create_file_writer('logs/train') \n",
    "    # Run training.\n",
    "    for _ in range(args.epochs): \n",
    "        train(gan, ds, args.save_iter, train_summary_writer) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c21fc655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--image_dir IMAGE_DIR] [--batch_size BATCH_SIZE] [--epochs EPOCHS]\n",
      "                             [--hr_size HR_SIZE] [--lr LR] [--save_iter SAVE_ITER]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Artis\\AppData\\Roaming\\jupyter\\runtime\\kernel-b15b227f-167e-4a68-8cd8-2defd9c3cd6c.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ccfbde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
